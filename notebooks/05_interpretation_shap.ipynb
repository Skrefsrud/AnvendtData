{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c73927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glinux/Projects/Skole/AnvendtData/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test shape: (885, 13)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.io_utils import load_df\n",
    "\n",
    "X_TEST_PATH   = os.path.join(PROJECT_ROOT, \"data/processed/X_test.csv\")\n",
    "Y_TEST_PATH   = os.path.join(PROJECT_ROOT, \"data/processed/y_test.csv\")\n",
    "X_TRAIN_PATH  = os.path.join(PROJECT_ROOT, \"data/processed/X_train.csv\")\n",
    "\n",
    "RF_MODEL_PATH  = os.path.join(PROJECT_ROOT, \"models/rf_baseline.pkl\")\n",
    "XGB_MODEL_PATH = os.path.join(PROJECT_ROOT, \"models/xgb_classifier.pkl\")\n",
    "\n",
    "FIG_DIR     = os.path.join(PROJECT_ROOT, \"figures\")\n",
    "REPORTS_DIR = os.path.join(PROJECT_ROOT, \"reports\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "\n",
    "# data\n",
    "X_test = load_df(X_TEST_PATH)\n",
    "y_test = load_df(Y_TEST_PATH)[\"Target\"]\n",
    "X_train_bg = load_df(X_TRAIN_PATH)\n",
    "\n",
    "# models\n",
    "rf_model  = joblib.load(RF_MODEL_PATH)\n",
    "xgb_model = joblib.load(XGB_MODEL_PATH)\n",
    "\n",
    "print(\"Loaded test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c9390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one; you can run the notebook twice to compare both\n",
    "model = rf_model        # or: xgb_model\n",
    "model_name = \"XGBoost\"  # or: \"XGBoost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c02f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TreeExplainer failed, falling back to model-agnostic SHAP: 'RandomForestClassifier' object has no attribute 'get_booster'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 501it [17:58,  2.16s/it]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP backend used: model-agnostic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# background sample for interventional SHAP (future-proof)\n",
    "bg_size = min(500, len(X_train_bg))\n",
    "background = X_train_bg.sample(n=bg_size, random_state=42)\n",
    "\n",
    "# sample test rows to explain\n",
    "X_sample = X_test.sample(n=min(500, len(X_test)), random_state=42)\n",
    "\n",
    "backend = None\n",
    "try:\n",
    "    if model_name == \"Random Forest\":\n",
    "        explainer = shap.TreeExplainer(\n",
    "            model,\n",
    "            data=background,\n",
    "            feature_perturbation=\"interventional\",\n",
    "            model_output=\"raw\"\n",
    "        )\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "        backend = \"tree-interventional\"\n",
    "\n",
    "    elif model_name == \"XGBoost\":\n",
    "        explainer = shap.TreeExplainer(\n",
    "            model.get_booster(),\n",
    "            data=background,\n",
    "            feature_perturbation=\"interventional\"\n",
    "        )\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "        backend = \"xgb-tree-interventional\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"TreeExplainer failed, falling back to model-agnostic SHAP:\", e)\n",
    "    explainer = shap.Explainer(model.predict_proba, background, algorithm=\"permutation\")\n",
    "    shap_values = explainer(X_sample)\n",
    "    backend = \"model-agnostic\"\n",
    "\n",
    "print(f\"SHAP backend used: {backend}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d460a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _drop_bias_col(arr, n_feat):\n",
    "    return arr[:, :-1] if arr.shape[1] == n_feat + 1 else arr\n",
    "\n",
    "def _fix_shapes(shap_vals, X):\n",
    "    # list of arrays (multiclass)\n",
    "    if isinstance(shap_vals, list):\n",
    "        return [_drop_bias_col(sv, X.shape[1]) for sv in shap_vals]\n",
    "    # Explanation object (new API)\n",
    "    try:\n",
    "        from shap._explanation import Explanation  # noqa: F401\n",
    "        if isinstance(shap_vals, Explanation):\n",
    "            return shap_vals\n",
    "    except Exception:\n",
    "        pass\n",
    "    # ndarray (legacy path)\n",
    "    if isinstance(shap_vals, np.ndarray):\n",
    "        return _drop_bias_col(shap_vals, X.shape[1])\n",
    "    return shap_vals\n",
    "\n",
    "fixed = _fix_shapes(shap_values, X_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9826f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2335/4130512506.py:36: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(fixed, X_sample, show=False, plot_size=(8,6))\n"
     ]
    }
   ],
   "source": [
    "fig_base = f\"{model_name.lower()}\"\n",
    "\n",
    "# Case A: list of arrays (multiclass tree backend)\n",
    "if isinstance(fixed, list):\n",
    "    shap.summary_plot(fixed, X_sample, show=False, plot_size=(8,6))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, f\"{fig_base}_shap_summary.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    # Per-class summaries (optional)\n",
    "    labels = [\"Dropout\", \"Graduate\", \"Enrolled\"]\n",
    "    for i, lbl in enumerate(labels[:len(fixed)]):\n",
    "        shap.summary_plot(fixed[i], X_sample, show=False, plot_size=(8,6))\n",
    "        plt.title(f\"{model_name} — SHAP Summary ({lbl})\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(FIG_DIR, f\"{fig_base}_shap_{lbl.lower()}.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "else:\n",
    "    # Case B: Explanation object (model-agnostic)\n",
    "    try:\n",
    "        from shap._explanation import Explanation\n",
    "        if isinstance(fixed, Explanation):\n",
    "            shap.plots.beeswarm(fixed, max_display=20, show=False)\n",
    "            plt.title(f\"{model_name} — SHAP Summary (Beeswarm)\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(FIG_DIR, f\"{fig_base}_shap_summary.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "        else:\n",
    "            # Case C: ndarray -> legacy summary_plot\n",
    "            shap.summary_plot(fixed, X_sample, show=False, plot_size=(8,6))\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(FIG_DIR, f\"{fig_base}_shap_summary.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "    except Exception:\n",
    "        shap.summary_plot(fixed, X_sample, show=False, plot_size=(8,6))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(FIG_DIR, f\"{fig_base}_shap_summary.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe75b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/glinux/Projects/Skole/AnvendtData/reports/xgboost_shap_importance.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>mean_abs_shap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overall_approval_rate</td>\n",
       "      <td>0.126282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_approved_units</td>\n",
       "      <td>0.053210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>average_grade</td>\n",
       "      <td>0.047040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuition fees up to date</td>\n",
       "      <td>0.033748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Age at enrollment</td>\n",
       "      <td>0.031198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scholarship holder</td>\n",
       "      <td>0.023923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.009709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unemployment rate</td>\n",
       "      <td>0.009395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GDP</td>\n",
       "      <td>0.008966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Inflation rate</td>\n",
       "      <td>0.008132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  mean_abs_shap\n",
       "2     overall_approval_rate       0.126282\n",
       "1      total_approved_units       0.053210\n",
       "0             average_grade       0.047040\n",
       "3   Tuition fees up to date       0.033748\n",
       "6         Age at enrollment       0.031198\n",
       "5        Scholarship holder       0.023923\n",
       "7                    Gender       0.009709\n",
       "9         Unemployment rate       0.009395\n",
       "11                      GDP       0.008966\n",
       "10           Inflation rate       0.008132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Robust global mean |SHAP| (always returns 1-D per feature) ---\n",
    "def global_mean_abs_shap(fixed_values, X):\n",
    "    import numpy as np\n",
    "    # Case 1: list of per-class arrays\n",
    "    if isinstance(fixed_values, list):\n",
    "        # average mean|SHAP| across classes\n",
    "        per_class = [np.abs(sv).mean(axis=0) for sv in fixed_values]  # (n_features,)\n",
    "        return np.mean(per_class, axis=0)  # (n_features,)\n",
    "\n",
    "    # Try Explanation API\n",
    "    try:\n",
    "        from shap._explanation import Explanation  # type: ignore\n",
    "        if isinstance(fixed_values, Explanation):\n",
    "            vals = fixed_values.values\n",
    "            # shapes: (n_samples, n_features) OR (n_samples, n_features, n_outputs)\n",
    "            if vals.ndim == 2:\n",
    "                return np.abs(vals).mean(axis=0)  # (n_features,)\n",
    "            elif vals.ndim == 3:\n",
    "                return np.abs(vals).mean(axis=(0, 2))  # (n_features,)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # ndarray fallback\n",
    "    arr = np.asarray(fixed_values)\n",
    "    if arr.ndim == 2 and arr.shape[1] in (X.shape[1], X.shape[1] + 1):\n",
    "        # (n_samples, n_features [+ bias])\n",
    "        if arr.shape[1] == X.shape[1] + 1:\n",
    "            arr = arr[:, :-1]\n",
    "        return np.abs(arr).mean(axis=0)\n",
    "    elif arr.ndim == 3:\n",
    "        # could be (n_outputs, n_samples, n_features) or (n_samples, n_features, n_outputs)\n",
    "        if arr.shape[-1] == X.shape[1]:   # (..., n_features)\n",
    "            return np.abs(arr).mean(axis=(0, 1))\n",
    "        elif arr.shape[-2] == X.shape[1]: # (..., n_features, ...)\n",
    "            return np.abs(arr).mean(axis=(0, 2))\n",
    "    raise ValueError(f\"Unhandled SHAP value shape: {arr.shape}\")\n",
    "\n",
    "mean_abs = global_mean_abs_shap(fixed, X_sample)\n",
    "\n",
    "# now this will be 1-D and align with columns\n",
    "imp_df = (\n",
    "    pd.DataFrame({\"feature\": X_sample.columns, \"mean_abs_shap\": mean_abs})\n",
    "      .sort_values(\"mean_abs_shap\", ascending=False)\n",
    ")\n",
    "\n",
    "imp_path = os.path.join(REPORTS_DIR, f\"{fig_base}_shap_importance.csv\")\n",
    "imp_df.to_csv(imp_path, index=False)\n",
    "print(\"Saved:\", imp_path)\n",
    "imp_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7815a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class table skipped (not a multiclass tree backend).\n"
     ]
    }
   ],
   "source": [
    "labels = [\"Dropout\", \"Graduate\", \"Enrolled\"]\n",
    "\n",
    "if isinstance(fixed, list) and len(fixed) == 3:\n",
    "    per_class_tables = []\n",
    "    for i, lbl in enumerate(labels):\n",
    "        mean_abs_i = np.abs(fixed[i]).mean(0)\n",
    "        df_i = pd.DataFrame({\n",
    "            \"feature\": X_sample.columns,\n",
    "            \"mean_abs_shap\": mean_abs_i,\n",
    "            \"class\": lbl\n",
    "        }).sort_values(\"mean_abs_shap\", ascending=False).head(10)\n",
    "        per_class_tables.append(df_i)\n",
    "    per_class_df = pd.concat(per_class_tables, ignore_index=True)\n",
    "    out_path = os.path.join(REPORTS_DIR, f\"{fig_base}_shap_top10_per_class.csv\")\n",
    "    per_class_df.to_csv(out_path, index=False)\n",
    "    print(\"Saved per-class top10:\", out_path)\n",
    "else:\n",
    "    print(\"Per-class table skipped (not a multiclass tree backend).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e40982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependence plots for: overall_approval_rate, total_approved_units, average_grade, Tuition fees up to date, Age at enrollment\n"
     ]
    }
   ],
   "source": [
    "# ---- Robust dependence plots (manual scatter) ----\n",
    "from shap._explanation import Explanation  # noqa: F401\n",
    "\n",
    "top_feats = imp_df[\"feature\"].head(5).tolist()\n",
    "labels = [\"Dropout\", \"Graduate\", \"Enrolled\"]\n",
    "\n",
    "def _dep_plot_manual(feat, shap_vals, X, save_path, class_idx=0):\n",
    "    j = X.columns.get_loc(feat)\n",
    "    x = X.iloc[:, j].values\n",
    "\n",
    "    # Case A: list of per-class arrays (TreeExplainer, multiclass)\n",
    "    if isinstance(shap_vals, list):\n",
    "        sv = shap_vals[class_idx]  # (n_samples, n_features)\n",
    "        y = sv[:, j]\n",
    "\n",
    "    # Case B: Explanation object (model-agnostic/new API)\n",
    "    elif isinstance(shap_vals, Explanation):\n",
    "        vals = shap_vals.values\n",
    "        # shapes: (n_samples, n_features) OR (n_samples, n_features, n_outputs)\n",
    "        if vals.ndim == 2:\n",
    "            y = vals[:, j]\n",
    "        elif vals.ndim == 3:\n",
    "            # pick the class dimension\n",
    "            y = vals[:, j, class_idx]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected Explanation.values ndim: {vals.ndim}\")\n",
    "\n",
    "    # Case C: plain ndarray (legacy)\n",
    "    else:\n",
    "        arr = np.asarray(shap_vals)\n",
    "        if arr.ndim == 2:                  # (n_samples, n_features [+1 bias])\n",
    "            if arr.shape[1] == X.shape[1] + 1:\n",
    "                arr = arr[:, :-1]\n",
    "            y = arr[:, j]\n",
    "        elif arr.ndim == 3:\n",
    "            # try (n_outputs, n_samples, n_features)\n",
    "            if arr.shape[0] in (2, 3) and arr.shape[2] == X.shape[1]:\n",
    "                y = arr[class_idx, :, j]\n",
    "            # or (n_samples, n_features, n_outputs)\n",
    "            elif arr.shape[2] in (2, 3) and arr.shape[1] == X.shape[1]:\n",
    "                y = arr[:, j, class_idx]\n",
    "            else:\n",
    "                raise ValueError(f\"Unhandled ndarray shape for dependence: {arr.shape}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unhandled ndarray ndim: {arr.ndim}\")\n",
    "\n",
    "    # Clean NaNs / inf and ensure same length\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "    x, y = x[mask], y[mask]\n",
    "    if x.shape[0] != y.shape[0]:\n",
    "        raise ValueError(f\"x and y must be same size; got {x.shape[0]} and {y.shape[0]}\")\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(x, y, s=12, alpha=0.6)\n",
    "    plt.xlabel(feat)\n",
    "    plt.ylabel(f\"SHAP value ({labels[class_idx]})\")\n",
    "    plt.title(f\"{model_name} — Dependence: {feat} → {labels[class_idx]}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# Generate plots for top 5 features, focused on Dropout class by default (class_idx=0)\n",
    "for feat in top_feats:\n",
    "    out = os.path.join(FIG_DIR, f\"{fig_base}_shap_dependence_{feat}.png\")\n",
    "    _dep_plot_manual(feat, fixed, X_sample, out, class_idx=0)\n",
    "\n",
    "print(\"Saved dependence plots for:\", \", \".join(top_feats))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
