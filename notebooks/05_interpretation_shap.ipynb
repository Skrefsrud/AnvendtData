{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a92d89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, ast, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.io_utils import load_df  # keep your project loader\n",
    "\n",
    "X_TEST_PATH   = os.path.join(PROJECT_ROOT, \"data/processed/X_test.csv\")\n",
    "Y_TEST_PATH   = os.path.join(PROJECT_ROOT, \"data/processed/y_test.csv\")\n",
    "X_TRAIN_PATH  = os.path.join(PROJECT_ROOT, \"data/processed/X_train.csv\")\n",
    "\n",
    "RF_MODEL_PATH  = os.path.join(PROJECT_ROOT, \"models/rf_baseline.pkl\")\n",
    "XGB_MODEL_PATH = os.path.join(PROJECT_ROOT, \"models/xgb_classifier.pkl\")\n",
    "\n",
    "FIG_DIR     = os.path.join(PROJECT_ROOT, \"figures\")\n",
    "REPORTS_DIR = os.path.join(PROJECT_ROOT, \"reports\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c711f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (3539, 18) (885, 18) (885,)\n",
      "Dtypes (X_test):\n",
      " float64    10\n",
      "int64       8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use the project loader so it behaves the same as the rest of your pipeline\n",
    "X_train = load_df(X_TRAIN_PATH)\n",
    "X_test  = load_df(X_TEST_PATH)\n",
    "y_test  = load_df(Y_TEST_PATH).iloc[:, 0]  # first column as Series\n",
    "\n",
    "print(\"Shapes:\", X_train.shape, X_test.shape, y_test.shape)\n",
    "print(\"Dtypes (X_test):\\n\", X_test.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f71a1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_list_string(s: str) -> bool:\n",
    "    # quick heuristic: starts with [ and ends with ] and contains at least one comma or space-separated numbers\n",
    "    return isinstance(s, str) and s.strip().startswith(\"[\") and s.strip().endswith(\"]\")\n",
    "\n",
    "def try_parse_list(s: str):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except Exception:\n",
    "        return s  # keep original if parsing fails\n",
    "\n",
    "def expand_list_column(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    \"\"\"Expand a column containing list-like values into multiple numeric columns.\"\"\"\n",
    "    parsed = df[col].apply(lambda v: try_parse_list(v) if isinstance(v, str) else v)\n",
    "    # find the first list to infer length\n",
    "    first_list = next((v for v in parsed if isinstance(v, (list, tuple, np.ndarray))), None)\n",
    "    if first_list is None:\n",
    "        # nothing to expand, just return\n",
    "        return df\n",
    "    k = len(first_list)\n",
    "    # ensure all list-like values have same length k; coerce where possible\n",
    "    def coerce_to_len_k(v):\n",
    "        if isinstance(v, (list, tuple, np.ndarray)):\n",
    "            v = list(v)\n",
    "            if len(v) == k:\n",
    "                return v\n",
    "        # fallback: fill with NaNs\n",
    "        return [np.nan]*k\n",
    "\n",
    "    arr = np.vstack(parsed.apply(coerce_to_len_k).values)\n",
    "    new_cols = [f\"{col}_{i}\" for i in range(k)]\n",
    "    df[new_cols] = arr.astype(np.float32)\n",
    "    df = df.drop(columns=[col])\n",
    "    return df\n",
    "\n",
    "def coerce_object_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"For any object column, if it looks like a list-string in >=20% rows, expand it.\n",
    "       Otherwise try to cast to numeric; if fail, keep as-is to drop later.\"\"\"\n",
    "    df = df.copy()\n",
    "    obj_cols = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "    for col in obj_cols:\n",
    "        s = df[col].dropna().astype(str)\n",
    "        share_listlike = (s.map(looks_like_list_string)).mean() if len(s) else 0.0\n",
    "        if share_listlike >= 0.2:\n",
    "            df = expand_list_column(df, col)\n",
    "        else:\n",
    "            # try numeric cast\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"raise\")\n",
    "            except Exception:\n",
    "                # leave for now; we'll drop non-numeric later\n",
    "                pass\n",
    "    return df\n",
    "\n",
    "def enforce_numeric_and_align(X: pd.DataFrame, reference_columns: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"Ensure all columns are numeric; drop non-numeric; align column order to reference if provided.\"\"\"\n",
    "    X = coerce_object_columns(X)\n",
    "    # Drop any remaining non-numeric columns\n",
    "    numeric_X = X.select_dtypes(include=[np.number]).copy()\n",
    "    # float32 to be safe with SHAP & XGBoost\n",
    "    for c in numeric_X.columns:\n",
    "        if not np.issubdtype(numeric_X[c].dtype, np.number):\n",
    "            numeric_X[c] = pd.to_numeric(numeric_X[c], errors=\"coerce\")\n",
    "    numeric_X = numeric_X.astype(np.float32)\n",
    "\n",
    "    if reference_columns is not None:\n",
    "        # add missing columns as zeros\n",
    "        for col in reference_columns:\n",
    "            if col not in numeric_X.columns:\n",
    "                numeric_X[col] = 0.0\n",
    "        # drop extras not seen in reference\n",
    "        extra = [c for c in numeric_X.columns if c not in reference_columns]\n",
    "        if extra:\n",
    "            numeric_X = numeric_X.drop(columns=extra)\n",
    "        # reorder\n",
    "        numeric_X = numeric_X[reference_columns]\n",
    "    return numeric_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bff870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After sanitize -> X_train: (3539, 18) [dtype('float32')]\n",
      "After sanitize -> X_test: (885, 18) [dtype('float32')]\n"
     ]
    }
   ],
   "source": [
    "rf_model  = joblib.load(RF_MODEL_PATH)   # RandomForestClassifier\n",
    "xgb_model = joblib.load(XGB_MODEL_PATH)  # XGBClassifier (sklearn API)\n",
    "\n",
    "# Prefer model.feature_names_in_ if available for consistent ordering\n",
    "reference_cols = None\n",
    "for m in [xgb_model, rf_model]:\n",
    "    if hasattr(m, \"feature_names_in_\"):\n",
    "        reference_cols = list(m.feature_names_in_)\n",
    "        break\n",
    "\n",
    "X_train_sanitized = enforce_numeric_and_align(X_train, reference_cols)\n",
    "X_test_sanitized  = enforce_numeric_and_align(X_test,  reference_cols)\n",
    "\n",
    "print(\"After sanitize -> X_train:\", X_train_sanitized.shape, X_train_sanitized.dtypes.unique())\n",
    "print(\"After sanitize -> X_test:\",  X_test_sanitized.shape,  X_test_sanitized.dtypes.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb524d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell E (callable model fallback) ---\n",
    "\n",
    "def background_sample(X: pd.DataFrame, n: int = 200) -> pd.DataFrame:\n",
    "    if len(X) <= n:\n",
    "        return X\n",
    "    return X.sample(n=n, random_state=42)\n",
    "\n",
    "bg = background_sample(X_train_sanitized, n=200)\n",
    "\n",
    "masker = shap.maskers.Independent(bg)\n",
    "\n",
    "# Wrap predict_proba as a callable that returns class-1 probability\n",
    "def xgb_predict_proba1(X):\n",
    "    return xgb_model.predict_proba(X)[:, 1]\n",
    "\n",
    "def rf_predict_proba1(X):\n",
    "    return rf_model.predict_proba(X)[:, 1]\n",
    "\n",
    "xgb_explainer = shap.Explainer(\n",
    "    xgb_predict_proba1,\n",
    "    masker,\n",
    "    feature_names=list(X_train_sanitized.columns)\n",
    ")\n",
    "\n",
    "rf_explainer = shap.Explainer(\n",
    "    rf_predict_proba1,\n",
    "    masker,\n",
    "    feature_names=list(X_train_sanitized.columns)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7725f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TreeExplainer.__init__() got an unexpected keyword argument 'check_additivity'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m bg = background_sample(X_train_sanitized, n=BG_N)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Rebuild explainers with a faster perturbation for speed if you can tolerate a bit of bias under correlation\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Use \"tree_path_dependent\" for speed; keep \"interventional\" if you want stricter assumptions (slower).\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m xgb_explainer = \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTreeExplainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_perturbation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtree_path_dependent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# faster\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprobability\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_additivity\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m rf_explainer = shap.TreeExplainer(\n\u001b[32m     24\u001b[39m     rf_model,\n\u001b[32m     25\u001b[39m     data=bg,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     check_additivity=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     29\u001b[39m )\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Slice the test set (explaining fewer rows speeds everything up)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: TreeExplainer.__init__() got an unexpected keyword argument 'check_additivity'"
     ]
    }
   ],
   "source": [
    "# --- Speed knobs ---\n",
    "N_SLICE = 300\n",
    "BG_N    = 100\n",
    "\n",
    "def background_sample(X, n=BG_N):\n",
    "    if len(X) <= n:\n",
    "        return X\n",
    "    return X.sample(n=n, random_state=42)\n",
    "\n",
    "bg = background_sample(X_train_sanitized, n=BG_N)\n",
    "\n",
    "# Build explainers (no check_additivity here)\n",
    "xgb_explainer = shap.TreeExplainer(\n",
    "    xgb_model,\n",
    "    data=bg,\n",
    "    feature_perturbation=\"tree_path_dependent\",  # faster; switch to \"interventional\" if you prefer\n",
    "    model_output=\"probability\"\n",
    ")\n",
    "\n",
    "rf_explainer = shap.TreeExplainer(\n",
    "    rf_model,\n",
    "    data=bg,\n",
    "    feature_perturbation=\"tree_path_dependent\",\n",
    "    model_output=\"probability\"\n",
    ")\n",
    "\n",
    "# Slice test set for faster computation\n",
    "X_slice = (X_test_sanitized.sample(N_SLICE, random_state=42)\n",
    "           if len(X_test_sanitized) > N_SLICE else X_test_sanitized)\n",
    "\n",
    "# Call explainers â€” pass check_additivity here\n",
    "xgb_shap_values = xgb_explainer(X_slice, check_additivity=False)\n",
    "rf_shap_values  = rf_explainer(X_slice, check_additivity=False)\n",
    "\n",
    "print(\"Shapes -> X:\", X_slice.shape,\n",
    "      \"| XGB shap:\", getattr(xgb_shap_values.values, 'shape', None),\n",
    "      \"| RF shap:\", getattr(rf_shap_values.values, 'shape', None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6eaba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.summary_plot(xgb_shap_values, X_slice, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"shap_summary_xgb.png\"), dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "shap.summary_plot(rf_shap_values, X_slice, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, \"shap_summary_rf.png\"), dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
